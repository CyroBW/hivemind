{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "!pip install \"tensorflow[and-cuda]\"\n",
    "!pip install \"flax[all]\"\n",
    "!pip install gdown\n",
    "!pip install pgx\n",
    "!pip install tqdm\n",
    "!pip install pydantic\n",
    "!pip install git+https://github.com/aminwoo/pgx.git\n",
    "!pip install git+https://github.com/lowrollr/mctx-az.git\n",
    "\n",
    "!gdown https://drive.google.com/drive/folders/13FcUDoZC5bvKjel_5qlLEiWuhKD4V5zn?usp=sharing --folder\n",
    "\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return x * jnp.tanh(jax.nn.softplus(x))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AZResnetConfig:\n",
    "    num_blocks: int\n",
    "    channels: int\n",
    "    policy_channels: int\n",
    "    value_channels: int\n",
    "    num_policy_labels: int\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    channels: int\n",
    "    se: bool\n",
    "    se_ratio: int = 4\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train: bool):\n",
    "        y = nn.Conv(\n",
    "            features=self.channels, kernel_size=(3, 3), padding=(1, 1), use_bias=False\n",
    "        )(x)\n",
    "        y = nn.BatchNorm(use_running_average=not train)(y)\n",
    "        y = mish(y)\n",
    "        y = nn.Conv(\n",
    "            features=self.channels, kernel_size=(3, 3), padding=(1, 1), use_bias=False\n",
    "        )(x)\n",
    "        y = nn.BatchNorm(use_running_average=not train)(y)\n",
    "\n",
    "        if self.se:\n",
    "            squeeze = jnp.mean(y, axis=(1, 2), keepdims=True)\n",
    "\n",
    "            excitation = nn.Dense(\n",
    "                features=self.channels // self.se_ratio, use_bias=True\n",
    "            )(squeeze)\n",
    "            excitation = nn.relu(excitation)\n",
    "            excitation = nn.Dense(features=self.channels, use_bias=True)(excitation)\n",
    "            excitation = nn.hard_sigmoid(excitation)\n",
    "\n",
    "            y = y * excitation\n",
    "\n",
    "        return mish(x + y)\n",
    "\n",
    "\n",
    "class AZResnet(nn.Module):\n",
    "    config: AZResnetConfig\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, train: bool):\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x = nn.Conv(\n",
    "            features=self.config.channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            use_bias=False,\n",
    "        )(x)\n",
    "        x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "        x = mish(x)\n",
    "\n",
    "        for _ in range(self.config.num_blocks):\n",
    "            x = ResidualBlock(channels=self.config.channels, se=True)(x, train=train)\n",
    "\n",
    "        # policy head\n",
    "        policy = nn.Conv(\n",
    "            features=self.config.channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            use_bias=False,\n",
    "        )(x)\n",
    "        policy = nn.BatchNorm(use_running_average=not train)(policy)\n",
    "        policy = mish(policy)\n",
    "        policy = nn.Conv(\n",
    "            features=self.config.policy_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=(1, 1),\n",
    "            use_bias=False,\n",
    "        )(policy)\n",
    "        policy = nn.BatchNorm(use_running_average=not train)(policy)\n",
    "        policy = mish(policy)\n",
    "        policy = policy.reshape((batch_size, -1))\n",
    "        policy = nn.Dense(features=self.config.num_policy_labels)(policy)\n",
    "\n",
    "        # value head\n",
    "        value = nn.Conv(\n",
    "            features=self.config.value_channels, kernel_size=(1, 1), use_bias=False\n",
    "        )(x)\n",
    "        value = nn.BatchNorm(use_running_average=not train)(value)\n",
    "        value = mish(value)\n",
    "        value = value.reshape((batch_size, -1))\n",
    "        value = nn.Dense(features=256)(value)\n",
    "        value = mish(value)\n",
    "        value = nn.Dense(features=1)(value)\n",
    "        value = nn.tanh(value)\n",
    "        value = value.squeeze(axis=1)\n",
    "\n",
    "        return policy, value\n",
    "    \n",
    "\n",
    "import os\n",
    "\n",
    "from typing import Any\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import orbax.checkpoint as ocp\n",
    "import chex\n",
    "    \n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import random \n",
    "import time\n",
    "import requests\n",
    "from threading import Thread\n",
    "from functools import partial\n",
    "from typing import Optional, List\n",
    "\n",
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np \n",
    "import mctx\n",
    "import optax\n",
    "import pgx\n",
    "from pgx.bughouse import _time_advantage\n",
    "from flax.training import train_state\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_configs = AZResnetConfig(\n",
    "    num_blocks=15,\n",
    "    channels=256,\n",
    "    policy_channels=4,\n",
    "    value_channels=8,\n",
    "    num_policy_labels=2*64*78+1,\n",
    ")\n",
    "net = AZResnet(model_configs)\n",
    "options = ocp.CheckpointManagerOptions()\n",
    "mngr = ocp.CheckpointManager(\n",
    "    \"/kaggle/working\",\n",
    "    options=options,\n",
    "    item_handlers=ocp.PyTreeCheckpointHandler()\n",
    ")\n",
    "ckpt = mngr.restore(0)\n",
    "\n",
    "params = {\"params\": ckpt[\"params\"], \"batch_stats\": ckpt[\"batch_stats\"]}\n",
    "\n",
    "devices = jax.local_devices()\n",
    "num_devices = len(devices)\n",
    "print(\"Number of devices:\", num_devices)\n",
    "\n",
    "class Config(BaseModel):\n",
    "    env_id: pgx.EnvId = \"bughouse\"\n",
    "    seed: int = random.randint(0, 999999999)\n",
    "    max_num_iters: int = 1000\n",
    "    # selfplay params\n",
    "    selfplay_batch_size: int = 1\n",
    "    num_simulations: int = 800\n",
    "    max_num_steps: int = 512\n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "\n",
    "config: Config = Config()\n",
    "\n",
    "env = pgx.make(config.env_id)\n",
    "init_fn = jax.jit(jax.vmap(env.init))\n",
    "step_fn = jax.jit(jax.vmap(env.step))\n",
    "\n",
    "\n",
    "def recurrent_fn(params, rng_key: jnp.ndarray, action: jnp.ndarray, state: pgx.State):\n",
    "    rng_keys = jax.random.split(rng_key, config.selfplay_batch_size)\n",
    "    current_player = state.current_player\n",
    "    state = step_fn(state, action, rng_keys)\n",
    "\n",
    "    logits, value = net.apply(params, state.observation, train=False)\n",
    "\n",
    "    # mask invalid actions\n",
    "    logits = logits - jnp.max(logits, axis=-1, keepdims=True)\n",
    "    logits = jnp.where(state.legal_action_mask, logits, jnp.finfo(logits.dtype).min)\n",
    "\n",
    "    reward = state.rewards[jnp.arange(state.rewards.shape[0]), current_player]\n",
    "    value = jnp.where(state.terminated, 0.0, value)\n",
    "    discount = -1.0 * jnp.ones_like(value)\n",
    "    discount = jnp.where(state.terminated, 0.0, discount)\n",
    "\n",
    "    recurrent_fn_output = mctx.RecurrentFnOutput(\n",
    "        reward=reward,\n",
    "        discount=discount,\n",
    "        prior_logits=logits,\n",
    "        value=value,\n",
    "    )\n",
    "    return recurrent_fn_output, state\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(2, ))\n",
    "def run_mcts(state, key, num_simulations: int, params, tree: Optional[mctx.Tree] = None):\n",
    "    key1, key2 = jax.random.split(key)\n",
    "\n",
    "    logits, value = net.apply(params, state.observation, train=False)\n",
    "    root = mctx.RootFnOutput(prior_logits=logits, value=value, embedding=state)\n",
    "\n",
    "    policy_output = mctx.alphazero_policy(\n",
    "        params=params,\n",
    "        rng_key=key1,\n",
    "        root=root,\n",
    "        recurrent_fn=recurrent_fn,\n",
    "        num_simulations=num_simulations,\n",
    "        invalid_actions=~state.legal_action_mask,\n",
    "        search_tree=None,\n",
    "        qtransform=partial(mctx.qtransform_by_min_max, min_value=-1, max_value=1),\n",
    "    )\n",
    "    return policy_output\n",
    "\n",
    "\n",
    "@jax.pmap\n",
    "def selfplay(params, rng_key: jnp.ndarray):    \n",
    "    rng_key, sub_key = jax.random.split(rng_key)\n",
    "    keys = jax.random.split(sub_key, config.selfplay_batch_size)\n",
    "    state = init_fn(keys)\n",
    "    tree = None \n",
    "\n",
    "    i = 0 \n",
    "    obs = jnp.zeros((config.max_num_steps, 4096)) \n",
    "    policy_tgt = jnp.zeros((config.max_num_steps, 9985)) \n",
    "\n",
    "    def cond_fun(carry):\n",
    "        state, rng_key, *_ = carry\n",
    "        return ~state.terminated.all() \n",
    "\n",
    "    def body_fun(carry):\n",
    "        state, rng_key, obs, policy_tgt, i = carry\n",
    "        rng_key, sub_key = jax.random.split(rng_key)\n",
    "        policy_output = run_mcts(state, sub_key, config.num_simulations, params, tree)\n",
    "\n",
    "        obs = obs.at[i].set(state.observation.ravel())\n",
    "        policy_tgt = policy_tgt.at[i].set(policy_output.action_weights.ravel())\n",
    "\n",
    "        keys = jax.random.split(sub_key, config.selfplay_batch_size)\n",
    "        state = step_fn(state, policy_output.action, keys)\n",
    "        return state, rng_key, obs, policy_tgt, i + 1\n",
    "\n",
    "    state, rng_key, obs, policy_tgt, num_samples = jax.lax.while_loop(cond_fun, body_fun, (state, rng_key, obs, policy_tgt, i))\n",
    "    return obs, policy_tgt, num_samples, abs(state.rewards[0][0])\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running selfplay with initial seed\", config.seed)\n",
    "\n",
    "    params = jax.device_put_replicated(params, devices)\n",
    "    rng_key = jax.random.PRNGKey(config.seed)\n",
    "    \n",
    "\n",
    "    for _ in tqdm(range(config.max_num_iters)):\n",
    "        rng_key, subkey = jax.random.split(rng_key)\n",
    "        keys = jax.random.split(rng_key, num_devices)\n",
    "\n",
    "        obs, policy_tgt, num_samples, result = selfplay(params, keys)\n",
    "        result = np.array(result)\n",
    "        \n",
    "        obs = np.concatenate((obs[0][:num_samples[0]], obs[1][:num_samples[1]]))\n",
    "        policy_tgt = np.concatenate((policy_tgt[0][:num_samples[0]], policy_tgt[1][:num_samples[1]]))\n",
    "        value_tgt = [[], []]\n",
    "        for i in range(2):\n",
    "            for _ in range(num_samples[i]):\n",
    "                value_tgt[i].append(result[i])\n",
    "                result[i] *= -1\n",
    "            value_tgt[i] = value_tgt[i][::-1]\n",
    "        value_tgt = value_tgt[0] + value_tgt[1]\n",
    "                \n",
    "        now = datetime.datetime.now(datetime.timezone(datetime.timedelta(hours=0)))\n",
    "        filepath = f'/kaggle/working/training-run1-{now.strftime(\"%Y%m%d\")}-{now.strftime(\"%H%M\")}'\n",
    "        np.savez_compressed(filepath, obs=obs, policy_tgt=policy_tgt, value_tgt=value_tgt)\n",
    "\n",
    "        url = f\"http://ec2-3-84-181-213.compute-1.amazonaws.com:8000/upload\"\n",
    "        file = {\"file\": open(filepath + \".npz\", \"rb\")}\n",
    "\n",
    "        response = requests.post(url=url, files=file) \n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Game sent successfully!\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "\n",
    "\n",
    "\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
