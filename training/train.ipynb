{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np \n",
    "import jax.numpy as jnp\n",
    "import tensorflow as tf \n",
    "from architectures.azresnet import AZResnet, AZResnetConfig\n",
    "from trainer import TrainerModule\n",
    "from constants import POLICY_LABELS, BOARD_HEIGHT, BOARD_WIDTH, NUM_BUGHOUSE_CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "init_optimizer() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboard_planes\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove_planes\u001b[39m\u001b[38;5;124m\"\u001b[39m], data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_planes\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m     23\u001b[0m     train_loader \u001b[38;5;241m=\u001b[39m train_loader\u001b[38;5;241m.\u001b[39mshuffle(buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_checkpoint()\n\u001b[1;32m     28\u001b[0m policy_acc, value_acc \u001b[38;5;241m=\u001b[39m  trainer\u001b[38;5;241m.\u001b[39meval_model(val_loader, batch_size)\n",
      "File \u001b[0;32m~/Desktop/hivemind/training/trainer.py:196\u001b[0m, in \u001b[0;36mTrainerModule.train_model\u001b[0;34m(self, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_loader, val_loader, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Train model for defined number of epochs\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# We first need to create optimizer and the scheduler for the given number of epochs\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Track best eval accuracy\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     best_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: init_optimizer() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "trainer = TrainerModule(model_name=\"AZResNet\", model_class=AZResnet, model_configs=AZResnetConfig(\n",
    "    num_blocks=15,\n",
    "    channels=256,\n",
    "    policy_channels=4, \n",
    "    value_channels=8,\n",
    "    num_policy_labels=len(POLICY_LABELS)\n",
    "), optimizer_name='lion', optimizer_params={'learning_rate': 0.00001}, x=jnp.ones((batch_size, BOARD_HEIGHT, 2 * BOARD_WIDTH, NUM_BUGHOUSE_CHANNELS)))\n",
    "trainer.init_optimizer()\n",
    "\n",
    "\n",
    "data = np.load(\"../data/fics_training_data/checkpoint0.npz\")\n",
    "with tf.device('/CPU:0'):\n",
    "    val_loader = tf.data.Dataset.from_tensor_slices((data[\"board_planes\"][:2**12], data[\"move_planes\"][:2**12], data[\"value_planes\"][:2**12]))\n",
    "    val_loader = val_loader.shuffle(buffer_size=2**16).batch(batch_size)\n",
    "\n",
    "for path in glob.glob(\"../data/fics_training_data/*\"):\n",
    "    data = np.load(path)\n",
    "\n",
    "    with tf.device('/CPU:0'):\n",
    "        train_loader = tf.data.Dataset.from_tensor_slices((data[\"board_planes\"], data[\"move_planes\"], data[\"value_planes\"]))\n",
    "        train_loader = train_loader.shuffle(buffer_size=2**16).batch(batch_size)\n",
    "\n",
    "    trainer.train_model(train_loader, batch_size) \n",
    "    trainer.save_checkpoint()\n",
    "\n",
    "    policy_acc, value_acc =  trainer.eval_model(val_loader, batch_size)\n",
    "    print(policy_acc, value_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
